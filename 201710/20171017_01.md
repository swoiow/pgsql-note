## [未完待续] PostgreSQL\Greenplum Customer视角TODO      
                             
### 作者            
digoal            
            
### 日期             
2017-10-17        
              
### 标签            
PostgreSQL , Greenplum , TODO               
                        
----                        
                         
## 背景         
https://wiki.postgresql.org/wiki/Todo      
      
## PostgreSQL    
### 一、内置HA  
#### 1、多副本自动选主、自动HA  
  
#### 2、单副本HA  
  
### 二、sharding  
#### 1. 物理流复制备库，支持对外部表执行DML操作，因为它不修改本地数据，没有风险。      
      
此法，可以用于sharding库的中间层库的扩展。      
      
a, b, c, d。   
  
a为主库，b,c,d为从库。  a,b,c,d都作为中间库，使用postgres_fdw或其他fdw来做sharding。      
        
### 三、可靠性  
#### 1、同步模式可自动降级  
  
同步复制自动降级，自动锁定（设置降级后的延迟阈值）。      
  
#### 2. 自适应同步模式(流复制)      
增加一个同步模式，remote_delay，当SYNC standby节点的WAL接收延迟低于这个值时，使用local的提交方式，用户COMMIT时，不进入等待队列。      
      
例如remote_delay=8KB      
      
那么当延迟低于8KB时，COMMIT或ROLLBACK不需要等待wal发送给备库，也就是说不需要进入sleep状态，本地REDO落盘后就提交。      
      
#### 3. 单步入库优化      
批量入库FEATURE      
      
5个开关 ：     
是否允许自动回滚，      
批量提交QUERY数，      
批量提交tuple影响数，      
idle in transaction 超时参数      
是否开启自动的savepoint      
      
自动分批提交特性：  
如果没有在事务中，则自动开启BEGIN      
到达阈值自动提交，并自动开启BEGIN      
      
允许用户选择是否自动回滚      
      
需要注意snapshot too old目前不处理写事务过旧。      
需要注意9.6以前的版本，长事务可能导致膨胀。      
      
应用场景：  
业务有大量的写入，      
业务不想改SQL，就是单条单条插入      
在同步多副本环境中特别有效。      
      
效果与 sync=off 类似      
但是记录批次可控，同时用户可感知，自动回滚到前一个savepoint。      
安全性比sync=off高。      
      
#### 4. 同步复制COMMIT延迟性能改进      
目前同步复制，事务提交时在一个队列中等待WAL SENDER获取到的RMT LSN进行释放。 导致大量的MUTEX锁，同时很多进程的等待可能是无效的。      
      
建议改成进程自己去询问RMT的LSN。      
      
采用N个预先建立的primary到standby(s)的连接，根据主节点backend process PID取模，自动选择对应的链路去询问。      
      
询问的LSN，分为几个(wal receiver(to buffer), wal write, wal flush ,wal apply)，询问到的LSN同时也通知给其他进程，其他进程也一样，自己去询问，同时接受别人询问的结果，一伙人去询问，可能效率更高。      
      
进程根据不同的级别，选择需要比较的COMMIT LSN与RMT LSN，进行释放。      
      
#### 5. flashback query支持      
1、允许用户设置表级vacuum 保留版本数，延迟VACUUM，同时延迟清理PG_XLOG，PG_CLOG。      
      
用户指定falshback的时间，查询当时的表快照。      
      
指定时间时，根据扫描到的XMIN或XMAX，在PG_XLOG中判断事务的提交时间，以及pg_clog中的事务结束状态，判断对用户是否可见。      
      
如果事务提交时间早于FLASHBACK时间，并且PG_CLOG事务结束状态为提交，则对用户可见。      
      
2、postgresql, 支持flashback, 例如postgresql 主备切换时，老的主库在没有配置recovery.conf时启动并有写入，导致分裂。使用flashback可以快速回到上一个时间线。      
      
使用pg_rewind可以实现同样功能。内部实现可以在启动后记录若干个变更的UNDO，从而实现可以回退。      
    
### 四、索引  
#### 1. 当使用GIN索引，并且大量使用了LIMIT来限制输出时，建议使用rum索引方法。避免bitmap index scan的recheck耗时。      
根据场景自动选择gin\rum索引的需求。  
  
#### 2. PostgreSQL , 在创建分区表索引时，支持每个分区并行创建。      
      
#### 3. PostgreSQL , paralle append + 外部表 + pushdown，可以实现sharding 架构下的并发计算。（例如求SUM,AVG,COUNG,MIN,MAX等，不过针对外部表的parallel append内核层面还没有支持好，需要CUSTOM SCAN）      
      
#### 4. PostgreSQL, 支持单个索引含多颗树 。       
      
[《PostgreSQL 店铺运营实践 - JSON[]数组 内部标签数据等值、范围检索100倍+加速示例》](../201802/20180208_01.md)        
      
分区索引。    
    
#### 5. 支持分区索引。一个索引根据某些表达式、字段HASH、范围分区，构成多颗树。（时间、空间、多个属性）      
      
#### 6. GIN索引支持范围扫描（目前仅支持等值(包含、相交等)扫描）。      
      
```      
arr >>= ? and arr <<=?      
```      
      
使用新的操作符代替```>=, <=，```实现元素的区间扫描。      
      
      
#### 7. 假设索引      
虚拟索引，查看执行计划的变化，有多少提升。    
  
PPAS 10已支持。    
  
#### 8. PostgreSQL 支持多种索引接口，支持自动选择合适的索引接口。      
      
[《PostgreSQL 9种索引的原理和应用场景》](../201706/20170627_01.md)        
      
[《自动选择正确索引访问接口(btree,hash,gin,gist,sp-gist,brin,bitmap...)的方法》](../201706/20170617_01.md)        
      
      
#### 9. btree, gist等 (非gin)索引，支持pending list特性，提升含索引时的数据写入性能。        
  
#### 10. gin支持条式返回，而非全量扫描index token后再返回。类似图式搜索的纵向(按点)返回和横向(层级返回)返回特性。      
  
#### 11. 支持index skip scan  
目前通过cte递归来支持    
      
#### 12. 全局索引（分区表全局大索引），继承表全局大索引，多表伪索引。      
      
      
### 五、性能  
#### 1. PostgreSQL，全表扫描支持通过hint或开关来使用directio，不占用OS CACHE，支持不加载到SHARED BUFFER。      
目前大表扫描，超过四分之一SHARED BUFFER的表，会设置FLAG，分批读取，并优先刷出SHARED BUFFER，防止扫描大表时SHARED BUFFER的抖动。  
      
### 六、功能  
#### 1. PostgreSQL，每个DB有单独的REDO，DB支持热插拔。支持DB级的物理流复制。一个集群的数据库可以物理流复制的模式拷贝到另一个集群。     
      
Oracle 18c 已支持      
      
#### 2. postgresql , 并行写wal。目前极限写压力下，WAL会成为瓶颈。        
    
#### 3. PostgreSQL，update returning old.column        
        
#### 4. PostgreSQL，列存储，支持并行的列存储。      
      
#### 5. PostgreSQL， online ddl , 可以改进pg_repack来支持ONLINE DDL。       
      
#### 6. pgbench 支持动态对象名，例如      
      
```      
\set suffix random(1,128)      
\set id random(1,10000000)      
      
select * from tbl:suffix where id=:id;      
```      
    
#### 7. 类似GIT的PG函数语言的版本迭代控制  
pg的存储过程接口非常丰富，用到的用户也非常多，版本控制的功能非常重要。  
    
#### 8. postgresql , HTAP业务，资源队列管理，资源隔离，进程组管理.      
      
#### 9. grouping sets, rollup, cube, grouping id函数         
      
http://blog.csdn.net/huang_xw/article/details/6402396      
      
#### 10. grouping()、grouping_id()、group_id()      
      
1 grouping()      
参数只有一个，而且必须为group by中出现的某一列，表示结果集的一行是否对该列做了grouping。对于对该列做了grouping的行而言，grouping()=0，反之为1；      
      
2 grouping_id()      
参数可以是多个，但必须为group by中出现的列。Grouping_id()的返回值其实就是参数中的每列的grouping()值的二进制向量，例如如果grouping(A)=1，grouping(B)=0，则grouping_id(A,B)的返回值就是二进制的10，转成10进制就是2。      
      
3 group_id()      
无参数。见上面的说明3），group by对某些列的集合会进行重复的grouping，而实际上绝大多数情况下对结果集中的这些重复行是不需要的，那就必须有办法剔出这些重复grouping的行。当结果集中有n条重复grouping而形成的行时，每行的group_id()分别是0,1,…,n，这样我们在条件中加入一个group_id()<1就可以剔出这些重复grouping的行了。      
      
#### 11. count(distinct) 目前只支持GroupAggregate，希望加入HashAggregate支持。同时支持HashAggregate的并行计算。      
      
#### 12. grant select on table 可以直接扣减 revoke select on table (column)。而不是只能grant select on table (column)来控制列的查询权限。      
      
#### 13. 统计信息、元数据信息快照，用于回放SQL，得到过去的执行计划信息。      
      
#### 14. 时间区间统计信息，统计信息分段快照，ORACLE已有功能，可以生成SQL在历史某个时间的执行计划。      
  
#### 15. jsonb, json, hstore类型, range类型，支持内部KEY，VALUE，范围分布的统计信息（柱状图，高频词等）。      
  
#### 16. logical slot支持filter tables
目前只能使用逻辑订阅支持，建议可以UDF化，通过UDF可以控制TABLE放到对应SLOT中。  
      
### 七、可视化生态：      
#### 1. 好的可视化监控软件
      
#### 2. 打通elastic和postgresql      
      
pgsql的数据实时同步到elastic      
      
https://developer.atlassian.com/blog/2015/02/realtime-requests-psql-elasticsearch/      
      
https://github.com/jprante/elasticsearch-jdbc/wiki/Step-by-step-recipe-for-setting-up-the-river-with-PostgreSQL      
      
https://github.com/jprante/elasticsearch-jdbc      
      
pgsql直接访问elastic的数据      
      
https://github.com/Mikulas/pg-es-fdw      
      
#### 3. 改进Orange，支持kibana所有可视化分析功能(图、地理、。。。。)      
      
https://orange.biolab.si/        
      
#### 4. 改进kibana，兼容postgresql      
        
https://www.elastic.co/products/kibana      
        
### 八、GIS  
#### 1. 改进qgis，稳定性，功能。云端GIS服务      
        
https://qgis.org/en/site/      
        
#### 2. arcgis合作      
      
#### 3. 其他      
      
http://openbouquet.io/      
      
http://grafana.org/      
      
http://redash.io/      
      
人才方向，可视化，GIS      
      
https://www.llamasoft.com/      
      
### 九、PostgreSQL 内核    
#### 1. 社区roadmap       
      
https://wiki.postgresql.org/wiki/Development_information      
      
#### 2. 一些社区企业ROADMAP       
      
https://postgrespro.com/roadmap/      
      
https://wiki.postgresql.org/wiki/NTT_roadmap      
  
#### 3. postgresql, 更新合并，对应秒杀场景(库存扣减)。      
      
    
     
#### 4. query rewrite: 自动消除含unique 约束的group by, 例如 unique (c1,c2)， 自动消除 group by c1,c2,...；      
      
#### 5. postgresql 内置qps统计能力，增强pg_stats进程的功能。      
      
        
#### 6. split range 类型，返回range数组    
      
#### 7. range数组操作      
      
```      
range[] - range[]  减      
  
range[] + range[]  加      
  
range[] & range[]  相交      
  
| range[] , 合并相邻或重叠的元素      
```      
      
#### 8. 支持rotate_table, 行，时间，SIZE等维度。      
      
#### 9. 支持returning语法，update时支持返回new, old值。      
      
  
#### 10. 通过HINT 在dml中包含begin, end事务标记      
减少交互次数，直接在QUERY中包含begin或END，ROLLBACK的包。      
      
减少交互次数。      
      
例如      
      
```    
      
select /*+ begin */ x from tbl;      
自动开启事务      
      
update /+ end */ t set xx=xx where xx;      
update /+ commit */ t set xx=xx where xx;      
自动提交当前事务      
      
update /*+ rollback */ t set xx=xx where xx;      
自动回滚当前事务      
```    
      
      
  
#### 11. 测试流量分流支持      
通过定义规则，实现对测试流量的分流。      
      
目前类似双十一或者其他公司在搞大促，或者对系统进行压测时，会模拟测试请求，这些请求不应该直接写入生产表。      
      
可以写到影子表，例如TBL对应的影子表TBL_TEST。      
      
PG可以根据客户端IP，客户端端口，application_name判断客户端是否属于测试来源。      
      
用户可以配置规则，将属于测试来源的数据，在query rewrite这一层，把SQL改写掉，TBL_TEST替代TBL。      
      
#### 12. PG connection pool      
内核层面的连接池。      
      
连接池考虑多个分组，用户可以自定义使用哪个分组，或者默认根据QUERY的读写特性区分分组，或者根据QUERY的时长区分分组。      
      
#### 13. pg_hba.conf 支持区分控制superuser权限      
目前pg_hba.conf仅支持角色名，库名。  
  
  
但是不能区分角色是普通用户还是超级用户。      
      
增加这个功能可以用来控制更细粒度的权限。      
      
例如禁止超级用户从远程登录。(现有的方法，把所有超级用户列一遍，但是当用户权限变更（例如从超级用户变成了普通用户）后，PG_HBA.CONF并不会变更。)      
      
#### 14. 释放CACHE      
syscache    
    
relcache    
    
buffer    
      
#### 15. 脏读功能      
      
read uncommitted 隔离级别  
  
      
#### 16. 解读数据文件的命令行工具或UDF  
      
从数据文件直接读取数据文件的内容。类似灾难恢复  
  
#### 17. 负载策略，客户端就近选择节点      
[思路]      
      
一种负载策略。      
      
读负载均衡、或多master的场景，客户端(最终客户端或proxy)选择就近节点。      
      
例如多机房的场景，通过IP地址判断先从哪个节点读。      
      
或者根据配置的节点顺序进行，直到取到正常节点为止(pg-jdbc目前是这种方式)。      
      
      
#### 18. redo, log日志分离      
目前PG所有日志都打印在一起，不利于日志分析。      
      
建议将审计日志、错误日志、慢SQL日志(包括auto_explain的)、其他日志分开成4个文件打印。      
      
      
#### 19. 并行恢复、未达到一致性点之前，恢复过程允许只读操作，自动过滤不一致数据块，或自动使用旧快照。   快速打开库允许只读。    
      
#### 20. 在log_min_duration和 auto_explain记录的SQL中记录锁等待的时长      
      
#### 21. 使用copy导入数据时，跳过异常的行。      
      
#### 22. walsender支持restore_command取文件传送给walreceiver      
      
      
#### 23. 自动校准成本因子, 维度支持      
自动校准cost因子，让实例得到最准确的执行计划      
      
      
#### 24. 支持多种数据块规格      
支持不同业务形态的表，采用不同的块大小。  
  
#### 25. 支持设置EXTEND BLOCK大小  
默认每次EXTEND 1个BLOCK，批量导入时性能有提升空间。  
  
[《PostgreSQL 单表并行bulkload的extend file lock 冲突问题解决》](../201805/20180515_03.md)    
      
      
#### 26. 批量数据提交   
PG如果能将插入这块的消息协议改进一下也许性能能提高比较多，将目前的 ESES..ES 改为 EEE...S 就好了。这样就可以实现类似于批量插入了。      
      
      
#### 27. pg_basebackup 过滤 hash index & unlogged table      
      
      
#### 28. 自动预热缓存      
      
      
#### 29. 资源隔离 : 会话级、用户级、语句级、库级 内存、CPU单位时间、IOPS  限制      
      
      
#### 30. 截断聚合      
截断头尾百分比后输出聚合值。类似的应用场景有排除噪点、干扰数据后的聚合。      
  
例如统计tps的平均值，方差，标准差。但是由于一些干扰因素可能导致测试TPS时造成了一些干扰，使用这种方法可以过滤掉一些干扰数据。      
      
http://api.pgxn.org/src/trimmed_aggregates/      
      
#### 31. 语法层面支持count采用输出  
允许用户选择需要精确count还是评估COUNT    
    
结合pg_class.reltuples    
    
结合sample语法，输出采样    
      
      
#### 32. libpq协议层压缩支持      
      
      
#### 33. 基于hash聚合的count distinct支持      
      
      
#### 34. plan hint 支持      
      
      
#### 35. 改进垃圾回收进程，只保留需要的tuple版本，而不是最早事务之前的所有版本。      
      
      
#### 36. 便捷的各种数据类产品打通，同步。      
数据同步模块    
      
#### 37. postgresql, pg_stat_all_tables, 建议添加autovacuum, auto analyze, analyze, vacuum等存储为数组，记录最近N次的操作统计信息，包括每次扫描了多少BLOCK，产生了多少DIRTY PAGE等等。      
      
便于突发的IO或CPU的排错。 目前只记录最后一次，而且统计信息只能到LOG里面翻看，不够便捷。       
      
```      
-[ RECORD 57 ]------+---------------------------------------      
relid               | 16794      
schemaname          | public      
relname             | xxx      
seq_scan            | 0      
seq_tup_read        | 0      
idx_scan            | 7878      
idx_tup_fetch       | 29897      
n_tup_ins           | 48337      
n_tup_upd           | 0      
n_tup_del           | 0      
n_tup_hot_upd       | 0      
n_live_tup          | 765193      
n_dead_tup          | 0      
n_mod_since_analyze | 13404      
last_vacuum         |       
last_autovacuum     | 2018-01-16 17:42:57.694793+08      
last_analyze        |       
last_autoanalyze    | 2018-01-13 09:13:02.457322+08      
vacuum_count        | 0      
autovacuum_count    | 1      
analyze_count       | 0      
autoanalyze_count   | 1      
```      
      
  
      
#### 38. Greenplum, postgresql , 加入roaringbitmap，同时支持 多阶段并行聚合函数。      
      
    
      
#### 39. PostgreSQL, GPDB , jsonbd 一种内置压缩能力的JSON类型，实际上数据库内核也可以在数组、全文检索等其他多值类型上增加类似的压缩功能（相当于内置的数据字典能力），将字典化这个工作转嫁给数据库来实现。         
        
https://github.com/postgrespro/jsonbd        
        
```      
CREATE EXTENSION jsonbd;      
CREATE TABLE t(a JSONB COMPRESSION jsonbd);      
```      
    
  
#### 40. online split, merge 分区表.      
      
#### 41. postgresql, gpdb 支持动态执行计划，执行过程中根据实际的NODE扫描并返回的数据的统计信息，动态调整执行计划。      
      
#### 42. timescale , postgresql, 提供数据自动老化能力（自动有损压缩）。      
        
#### 43. postgresql, 支持具备阶段性可靠性的UNLOGGED TABLE，加速导入。      
        
#### 44. postgresql , skip locked , 返回未获得锁的行。以便再次处理。      
        
#### 45. 支持冻结从库的receiver进程，不接受主库的wal。目前仅支持replay的冻结。       
      
用途，在多副本的情况下，HA切换时，保证不出现脑裂。      
      
```      
 pg_catalog | pg_wal_replay_pause           | void                     |                     | normal      
 pg_catalog | pg_wal_replay_resume          | void                     |                     | normal      
```      
        
#### 47. 支持普通用户设置synchronous_commit  
citus, 元数据 2PC，同时要求每个节点的SLAVE，必须同步接收到DDL。  
  
保证元数据的全局一致性。   
    
#### 48. 多实例的监控管理  
当是企业中有多个数据库时，需要一个可以管理多个实例的软件。  
  
例如将问题优先暴露。  

#### 49. update|delete skip locked, nowait语法支持      
目前PG支持select xxx for update skip locked , nowait.      
      
但是不支持dml直接使用skip locked或者nowait      
      
不利于低延迟的同类需求，需要发多次QUERY，开启事务来支持。      
      
考虑添加直接的 update | delete skip locked, nowait 支持。      
  
#### 50. 支持基于index的sample scan
例如采用索引扫描返回很多条记录假设100万，用户需要在这100万随机挑选10000条，排序输出TOP -K。   
  
常用于大量数据搜索，例如推荐引擎。   
  
#### 51. pg_stat_statements 支持细粒度配置，比如只收集超过N秒的SQL，只收集某些表相关的SQL等。  
  
#### 52. PG支持类似ORACLE的表空间管理，而非每个对象对应相关的数据文件
[《PostgreSQL 单库对象过多，触发Linux系统限制 (ext4_dx_add_entry: Directory index full!) (could not create file "xx/xx/xxxxxx": No space left on device)》](../201804/20180410_04.md)  
  
[《PostgreSQL DaaS设计注意 - schema与database的抉择》](../201610/20161012_01.md)  
  
[《PostgreSQL 备库apply延迟(delay)原理分析与诊断》](../201703/20170301_01.md)  
  
#### 53. PostgreSQL支持DIO
避免多重BUFFER   
  
#### 54. PostgreSQL 支持更多的资源共享（session目前的relcache, syscache, work_mem都是独立的，期待共享），向Oracle PGA, SGA的设计看齐。
  
#### 55. PostgreSQL 支持脑裂函数，目前脑裂的话，只能在LOG中查看
    
主备异常切换时，老主库可能有未同步到备库的WAL，出现时间线分歧。但是在未来可能被demote为备库，实际上已经不能接上备库，如果1 MIN内再次发生HA，会导致切换到不该切换的库。  
  
加一个函数，防止脑裂(主备由于时间线错乱不可相互复制状态)，在备库的角色执行，判断当前主备是否处于脑裂状态。  
  
脑裂时，不能主动切换到脑裂的备库。（人为介入，如果主库不可恢复，可能需要人为修复）  
  
目前需要从LOG中判断  
  
```
2018-05-04 11:29:55.524 CST,,,28551,,5aebd38b.6f87,20,,2018-05-04 11:29:15 CST,,0,LOG,00000,"restarted WAL streaming at 118/EA000000 on timeline 5",,,,,,,,"WalReceiverMain, walreceiver.c:400",""
2018-05-04 11:29:55.534 CST,,,28551,,5aebd38b.6f87,21,,2018-05-04 11:29:15 CST,,0,LOG,00000,"replication terminated by primary server","End of WAL reached on timeline 5 at 118/EABAA6D0.",,,,,,,"WalReceiverMain, walreceiver.c:467",""
2018-05-04 11:29:55.535 CST,,,28547,,5aebd38b.6f83,14,,2018-05-04 11:29:15 CST,1/0,0,LOG,00000,"new timeline 6 forked off current database system timeline 5 before current recovery point 118/EABCA368",,,,,,,,"rescanLatestTimeLine, xlog.c:4347",""
```
  
以下为已有的判断依据，接收到的WAL小于REPLAY的WAL位置。说明本地库在作为主库角色时，有WAL没有同步给上游，所以出现接收到的WAL小于REPLAY的WAL位置。  
  
```
postgres=# select pg_last_wal_replay_lsn();
 pg_last_wal_replay_lsn 
------------------------
 118/EABCA368
(1 row)

postgres=# select pg_last_wal_receive_lsn();
 pg_last_wal_receive_lsn 
-------------------------
 118/EA000000
(1 row)
```
  
pg_last_wal_receive_lsn小于pg_last_wal_replay_lsn，或pg_last_wal_receive_lsn 为 NULL，都可以判断为脑裂。  
  
#### 56. PG 目前临时表不支持并行，可以考虑支持。  
   
#### 57. cluster增强
支持cluster ， 数据INSERT时动态聚集.  
  
数据按 segment组织，SEGMENT 内 尽量的保持按cluster id值聚集。   
  
prefetch 效果好 ，范围扫描，效率提升  
  
DB2, fsm，列表结构，并发写存问题    
  
fsm 打散，多个，随机挑选，降低写入冲突      
  
#### 58. failover slot
[《PostgreSQL slot failover》](../201805/20180516_01.md)  
  
#### 59. 改进slot
目前SLOT会导致主库不清理备库需要的垃圾版本，导致膨胀，CPU飙升等问题。  
  
改良，把这块的功能去掉，这块的功能还是需要feed back开关来控制。  
  
[《PostgreSQL slot failover》](../201805/20180516_01.md)  
  
#### 60. 改进目录结构
目前PG的一个DB在一个TBS中对应一个目录，如果这个DB在表空间下很多对象，可能打爆文件系统的INODE INDEX上限。  
  
建议，加一层目录，改进pg_filemap，比如按TABLE OID HASH一层。这样可以减少文件系统的INODE INDEX打爆。   
  
[《如何在CentOS 6.x x64系统中创建超过16TB的ext4文件系统》](../201609/20160918_01.md)  
  
#### 61. 分析能力增强
1、读写磁盘吞吐快照区间统计，区分索引，表，垃圾回收，FREEZE，AUTOANALYZE。分类统计。
   
2、锁等待时长快照区间统计，区分锁粒度，下钻到对象。
  
#### 62. range[]索引
例如一个范围类型的数组，不需要展开数据，即可对齐进行索引的包含检索。   
  
类似于range的倒排+GIST索引。   
  
#### 63. gis类型支持更完备的统计信息
GIS类型的统计信息不多，评估不准确。  
  
```
postgres=# select * from pg_stats where tablename='test' and attname='pos';
 schemaname | tablename | attname | inherited | null_frac | avg_width | n_distinct | most_common_vals | most_common_freqs | histogram_bounds | correlation | most_common_elems | most_common_elem_freqs | elem_count_histogram 
------------+-----------+---------+-----------+-----------+-----------+------------+------------------+-------------------+------------------+-------------+-------------------+------------------------+----------------------
 public     | test      | pos     | f         |         0 |        32 |         -1 |                  |                   |                  |             |                   |                        | 
(1 row)

postgres=# explain analyze select * from test where st_contains(st_setsrid(st_makebox2d(st_makepoint(119,60), st_makepoint(122,71)), 4326) , pos);
                                                                                                                                                                                                                                   QUERY PLAN
                                                                                                                                                                                                                                   
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Gather  (cost=0.00..2815576.91 rows=10033 width=553) (actual time=1.028..11177.961 rows=30100000 loops=1)
   Workers Planned: 12
   Workers Launched: 12
   ->  Parallel Seq Scan on test  (cost=0.00..2815576.91 rows=836 width=553) (actual time=0.048..2786.635 rows=2315385 loops=13)
         Filter: (('0103000020E610000001000000050000000000000000C05D400000000000004E400000000000C05D400000000000C051400000000000805E400000000000C051400000000000805E400000000000004E400000000000C05D400000000000004E40'::geometry ~ pos) AND 
_st_contains('0103000020E610000001000000050000000000000000C05D400000000000004E400000000000C05D400000000000C051400000000000805E400000000000C051400000000000805E400000000000004E400000000000C05D400000000000004E40'::geometry, pos))
 Planning time: 0.189 ms
 Execution time: 13554.917 ms
(7 rows)
```
  
[《PostgreSQL 空间类型统计信息不准确导致SQL执行计划不准(包含、相交查询)的优化实践》](../201807/20180711_02.md)    
      
### 十、安全  
#### 1. 自动隐藏隐私信息（如create user password, alter role.... password)      
      
#### 2. sql 防火墙      
  
#### 3. 支持每个USER多个密码，每个密码有对应的过期时间      
用户如果要更换DB密码，那么应用层可以做到非常平滑。  
      
#### 4. 表级访问秘钥      
  
#### 5. PG，GP， 数据采样（已支持）、脱敏功能。      
      
#### 6. 数据类型， 透明加密功能.      

#### 7. 块级透明加密
  
#### 8. pl language 执行沙盒，过滤有风险的操作。
  
#### 9. pl language 代码内容加密。  
  
### 十一、benchmark
#### 1. pgbench接入更加丰富的benchmark case支持
      
## Greenplum      
      
#### 1、自动垃圾回收，目前的调度太烂了      
      
#### 2、优化器（非分布键的点查，现在建立master-segment的耗费较大，目测可能是串行的，节点多的情况下可能会比较糟糕。），      
      
#### 3、master到segment的连接保持。      
        
#### 4、segment之间的interconnect使用POOL连接池，减少motion时会话多的问题。      
      
#### 5、客户端连接池(顶住高并发)，      
      
#### 6、UPDATE和DELETE的排他锁改进，目前是表级锁      
      
#### 7、订阅支持（类似逻辑复制）通过PGQ、消息队列...实现。      
      
https://wiki.postgresql.org/wiki/PGQ_Tutorial      
      
#### 8、greenplum segment节点开放读写      
      
#### 9、GIN倒排（很多用户需求）      
      
#### 10、pg_trgm插件（模糊查询、全文检索、相似搜索）      
  
#### 11、提高greenplum的Oracle兼容性，特别是存储过程，自定义函数的性能。  
      
#### 12. greenplum, 按虚拟字段(或按表达式)分区、分布键      
  
#### 13. greenplum, 大表, 多segment，analyze速度偏慢。原因可能是需要在SEGMENT采样，并发送给MASTER，然后在MASTER再生成统计信息的原因。 有优化空间。  
  
#### 14. greenplum, 广播结果的复用，下次调用前如果未修改，则不需要再次发起广播。同时有多个会话广播同一张表，只广播一遍，共享。     
  
#### 15. AO表考虑一下类似lsm tree理念，分级写入，解决单步insert的性能问题，膨胀问题。   
      
        
<a rel="nofollow" href="http://info.flagcounter.com/h9V1"  ><img src="http://s03.flagcounter.com/count/h9V1/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_12/viewers_0/labels_0/pageviews_0/flags_0/"  alt="Flag Counter"  border="0"  ></a>        
        
      
